# Retina Net

It is a generalized [Fast Region-based Convolutional Network (Fast R-CNN)](https://arxiv.org/pdf/1504.08083.pdf) architecture improved the prediction precision by adapting feature pyramid for feature augmentation. Two ouput heads mount on the feature pyramid net (FPN) modified from other CNNs (like residual-50 or VGG-16). The schematic view of the RetinaNet architecture showing below:

![ResNet Architecture](/img/docs/Image_arch_RetinaNet.png)

## Feature Pyramid Net (FPN)

The FPN is used as backbone to provide features in variaty of size. It is expected that the coarser features should have better semantically information while the signal with higher resolution features should have better spatial information. In the Retina Net architecture, the output layers from the ResNet $\lbrace C_2, C_3, C_4, C_5\rbrace$ is used to form the FPN and the outputs are denoted as $\lbrace P_2,P_3,P_4,P_5\rbrace$. The convolution over these FPN will servese like sliding windows over the original images as illustrated below:

![FPN sliding](/img/docs/Image_schematic_FPN.png)

## Anchor Boxes

The anchor box used in the RetinaNet is similar to the setup in the [Faster R-CNN](https://arxiv.org/pdf/1506.01497.pdf), an improved version of Fast R-CNN. The anchor boxes are the bounding boxes anchored on each sliding window location, as illustrated below:

![Anchor Boxes](/img/docs/Image_arch_AnchorBox.png)

A bounding box with a scale and aspect ratio is anchored at the center of the sliding window. Three aspect ratios, (2:1, 1:1, 1:2), and three scales, (1, 0.5, 0.25), are used so that there are 9 bounding boxes anchored for each sliding windows. 

## Heads


The features from FPN is used as input for two parallel subnets to make classification and box regression separately. 

### The Classification Subnet
A simple fully convolution net (FCN) is used to taking the features as inputs to classify the objects for each anchors. It has 4 hidden layers with $3\times3$ kernel, 256 channels and the ReLU is used as activations, and The output layer is a $3\times 3$ convolution layer with $K\times A$ outputs where $K$ is number of object types and $A$ is the anchor size (how many anchor boxes for each sliding window). The output shape should be $W\times H\times K\times A$ where $W\times H$ is the spatial coordinates of features and each spatial location is assigned anchor with size $A$ and each anchor is assigned a vector with length $K$ to represent the object type.

### The Regression Subnet
The architecture of the regression subnet is the same as the classification subnet except the output layer is $4\times A$ channels represented the coordinate of the bounding boxes.
The output shape is the $W\times H\times A\times 4$, each of $W\times H$ represents an anchor box with $A$ aspect ratios or scales, 4 digits are used to represents the coordinate of the box.

## Training Details

### Ground Truth Assignment
The three types of coordinates are used generally: The two point pixel coordinate $(x_{\text{min}},y_{\text{min}},x_{\text{max}},y_{\text{max}})$, the center plus size coordinate $(x, y, w, h)$ and a parametrized relative coordinates $(t_x, t_y, t_w, t_h)$ where

$$
t_x = (x-x_a)/w,\quad t_y=(y-y_a)/h,\quad t_w = \log(w/w_a), \quad t_h=\log(h/h_a),
$$
where $(x,y,w,h)$ and $(x_a,y_a,w_a,h_a)$ is the center-size coordinates of a box relative to the latter anchor box, respectively. The box regression targets are generated by assigning the ground truth boxes to the anchor boxes by intersection over union (IOU) defined as

$$
\text{IoU} = \frac{A\cap A_0}{A\cup A_0},
$$

where $A$ stands for the predicted area and $A_0$ is the truth area. The matching criterion is that two boxes are matched to each other if the IOU of them is larger than 0.5. Those matching IOU values between 0.4 to 0.5 are ignored (not used in the paper). The matching IOU below 0.4 is considered as unmatched. The higher the IOU, the better matching of two boxes. The largest IOU matching ground truth is assigned to the anchor boxes accordingly, both the class type and box coordinates.

### Loss Functions

Two types of loss functions are applied for classification and box regression, respectively. For the classification, a Focal loss is used for balancing the imbalance of the fraction of each classes in training samples. The definition of the Focal loss $FL(p,y)$ where $p\in[0,1]$ stands for the output estimation from model and $y$ is the ground truth which should be $y\in\lbrace \pm1\rbrace$, and

$$
FL(p,y) = -\alpha_t(1-p)^\gamma\log(p),
$$
where $p_t=p$ if $y=1$ and $p_t=1-p$ for other value of $y$. This loss function is equivalent to the cross-entropy when $\gamma =0$ and $\gamma=2$ is used in the paper.

The loss function for the box regression is defined as

$$
L_{\text{reg}}(p,y) = \sum_{v\in\lbrace x,y,w,h\rbrace}R_{L_1}(p_v-y_v),
$$
where 

$$
R_{L_1}(x)=\left\lbrace
\begin{array}{ll}
0.5x^2 & |x|<1, \newline
|x|-0.5 & \text{otherwise},
\end{array}
\right.
$$
where the $p,y$ stands for the estimation and the ground truth of the anchored boxes.

The total loss function $L$ is the sum of these two parts

$$
L(p,y) = \frac{1}{N}\sum^n_{i=1}FL(p^i,y^i)+\frac{1}{N}\sum_{i=1}^n\Theta(y^i)\cdot L_{\text{reg}}(p^i,y^i),
$$
where the normalization factor $N$ stands for the number of anchors assigned to a ground truth and $n$ stands for the total number of anchors. $\Theta(x)$ is a step function that will be 1 for $x>0$ and 0 otherwise.

